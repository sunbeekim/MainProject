from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
from typing import Dict
import uvicorn
from fastapi.middleware.cors import CORSMiddleware
import re
import asyncio
import logging
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('llama_server.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI()

# CORS ì„¤ì •
origins = [
    "http://localhost:8080",
    "http://localhost:3000",
    "http://gateway-container:8080",
    "http://core-container:8081",
    "http://assist-container:8082",
    "https://sunbee.world",
    "*"  # ê°œë°œ ì¤‘ì—ëŠ” ëª¨ë“  origin í—ˆìš©
]

logger.info("CORS ì„¤ì • ì´ˆê¸°í™”...")
logger.info(f"í—ˆìš©ëœ Origins: {origins}")

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

print("ëª¨ë¸ ë¡œë”© ì¤‘...")
# ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì‚¬ìš© (ë¼ì´ì„¼ìŠ¤ ì œí•œ ì—†ìŒ)
model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto",
)
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

class ChatRequest(BaseModel):
    message: str
    history: list = []
    sessionId: str  # sessionId ì¶”ê°€

# ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
session_histories = {}

@app.post("/api/fastapi/chat")
async def chat(request: ChatRequest) -> Dict[str, str]:
    try:
        # ìš”ì²­ ë¡œê¹… ê°•í™”
        logger.info(f"""
=== ìƒˆë¡œìš´ ì±„íŒ… ìš”ì²­ ===
ì‹œê°„: {datetime.now()}
ì„¸ì…˜ ID: {request.sessionId}
ë©”ì‹œì§€: {request.message}
íˆìŠ¤í† ë¦¬ ê¸¸ì´: {len(request.history)}
ìš”ì²­ í—¤ë”: {request.headers if hasattr(request, 'headers') else 'No headers'}
======================
""")
        
        # ì„¸ì…˜ë³„ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
        if request.sessionId not in session_histories:
            logger.info(f"ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘: {request.sessionId}")
            session_histories[request.sessionId] = []
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """
            You are the AI customer support agent for the Haru app. Your name is Luffy.

            ğŸ§­ Haru Chatbot Operating Philosophy

            Haru is a "market where hobbies become talents."
            It provides a space where anyone can share, trade, and experience their hobbies or skills with others.
            We aim to provide friendly and professional service that enriches users' experiences and encourages exploration.

            ğŸ¤– Luffy's Customer Support Guidelines

            Provide accurate and concise answers.

            Ensure consistency by considering the conversation context.

            Offer step-by-step guidance when explaining features.

            Redirect inquiries related to payment, personal data, or security to dedicated support.

            If unsure, honestly say "I'm not sure" instead of guessing.

            Respond with empathy and sincerity when users face difficulties.

            ğŸ“± Haru Core Features Summary

            Hobby-based Talent Market: Anyone can list products based on their hobbies and trade with other users.

            Matching & Communication: Real-time connection through chat and notifications.

            Location-based Discovery: Filter products based on the user's current location.

            Community Features: Enable lasting user relationships via small groups and competitions.

            ğŸ—ºï¸ Main Menu Navigation

            ğŸ  Main Navigation

            Main Page (/): Recommended and latest products

            Bottom Menu:

            Market, Chat, Notification, Location, My Page

            ğŸ” Account Management

            Login (/login), Sign Up (/signup), Password Recovery & Update

            Account Deletion (/delete-account)

            ğŸ›ï¸ Talent Marketplace

            Register Product (/product/register)

            Product List and Filtering

            Product Details (/product-details)

            Favorite Products (/mypage â†’ Products of Interest)

            ğŸ’¬ Chat System

            1:1 Chat Room (/chat/:email)

            AI Chatbot (/servicechat)

            Notifications sent during chat, application, and location sharing

            ğŸ“ Location-Based Features

            Set My Location (/my-location)

            Filter by Distance ("Nearby" feature)

            ğŸ’³ Payments & Transactions

            Card Registration and Management (/ocr-upload, /registered-card)

            View Payment and Transaction History

            Share location between seller and buyer

            ğŸ”” Notifications & Customer Center

            Notification Center (/notification)

            Customer Center (/cs-list)

            1:1 Inquiry (/inquiry-history)

            â“ Frequently Asked Questions (FAQ)

            Q. How do I register a product?
            â†’ Go to [Market] tab > Click the + button 'Register Product' and fill out the form.

            Q. How do I chat with another user?
            â†’ Click the 'Apply' button on the product detail page or go to the chat page.

            Q. How do I set my location?
            â†’ Tap the 'Location' icon in the bottom menu > Set My Location

            Q. Iâ€™m not receiving chat notifications.
            â†’ Check in [Settings] > Notification Preferences.

            Q. How do I make a payment?
            â†’ Currently not implemented.

            Q. Where can I see my listed products?
            â†’ [My Page] â†’ Product Management

            ğŸ’¡ Feature Suggestions or Bug Reports

            If you have suggestions like â€œI wish this feature existed,â€
            ğŸ‘‰ Customer Center > 1:1 Inquiry
            ğŸ‘‰ or AI Chatbot to leave your feedback!
            Weâ€™re always listening.

            ğŸ¯ What the Chatbot Does Best

            Explains how to use the app step-by-step

            Answers feature-related inquiries

            Provides guidance and empathy for bugs/errors

            Collects and summarizes user feedback
    
            """

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        full_prompt = f"<system>{system_prompt}</system>\n"

        print(f"\n=== ì„¸ì…˜ {request.sessionId}ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì‹œì‘ ===")
        print(f"íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ ìˆ˜: {len(request.history)}")

        # ì´ì „ ëŒ€í™” ë‚´ìš© ì¶”ê°€ (ìµœê·¼ 4ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©)
        for i, msg in enumerate(request.history[-4:]):
            print(f"\në©”ì‹œì§€ {i+1}:")
            print(f"ì‚¬ìš©ì: {msg['user']}")
            if "assistant" in msg:
                print(f"ì–´ì‹œìŠ¤í„´íŠ¸: {msg['assistant']}")
            full_prompt += f"<user>{msg['user']}</user>\n"
            if "assistant" in msg:
                full_prompt += f"<assistant>{msg['assistant']}</assistant>\n"

        # í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
        print(f"\ní˜„ì¬ ë©”ì‹œì§€: {request.message}")
        full_prompt += f"<user>{request.message}</user>\n<assistant>"

        print("\n=== ìµœì¢… í”„ë¡¬í”„íŠ¸ ===")
        print(full_prompt)
        print("=====================\n")

        # ì…ë ¥ ë©”ì‹œì§€ í† í°í™”
        inputs = tokenizer(full_prompt, return_tensors="pt").to(model.device)

        # ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •
        generation_config = {
            "max_length": 2048,
            "temperature": 0.7,
            "top_p": 0.95,
            "repetition_penalty": 1.15,
            "do_sample": True
        }

        # ğŸ”¹ ë¹„ë™ê¸° ì‹¤í–‰ìœ¼ë¡œ ë³€ê²½ (`asyncio.to_thread` ì‚¬ìš©)
        outputs = await asyncio.to_thread(
            model.generate,
            **inputs,
            **generation_config,
            pad_token_id=tokenizer.eos_token_id
        )

        # ì‘ë‹µ ë””ì½”ë”© ë° í”„ë¡¬í”„íŠ¸ ì œê±°
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        response = response.split("<assistant>")[-1].strip()
        # \nì€ ìœ ì§€í•˜ê³  ë‹¤ë¥¸ íƒœê·¸ë§Œ ì œê±°
        clean_response = re.sub(r"</?(?!br\b)[a-zA-Z0-9]+>", "", response).strip()
        print(clean_response)

        # ì‘ë‹µ ë¡œê¹…
        logger.info(f"""
=== ì‘ë‹µ ìƒì„± ì™„ë£Œ ===
ì„¸ì…˜ ID: {request.sessionId}
ì‘ë‹µ ê¸¸ì´: {len(clean_response)}
======================
""")
        return {"response": clean_response}

    except Exception as e:
        error_msg = f"ì—ëŸ¬ ë°œìƒ - ì„¸ì…˜ ID: {request.sessionId}, ì—ëŸ¬: {str(e)}"
        logger.error(error_msg)
        raise HTTPException(status_code=500, detail=error_msg)


if __name__ == "__main__":
    logger.info("=== LLaMA ì„œë²„ ì‹œì‘ ===")
    logger.info(f"ëª¨ë¸: {model_name}")
    # í˜¸ìŠ¤íŠ¸ë¥¼ 0.0.0.0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©
    logger.info("ì„œë²„ ì‹œì‘: host=0.0.0.0, port=8001")
    uvicorn.run(
        app, 
        host="0.0.0.0",  # ëª¨ë“  IPì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
        port=8001,
        log_level="info"
    )